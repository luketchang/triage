import { logger } from "@triage/common";
import * as fs from "fs/promises";
import * as path from "path";
import { CollectedFiles } from "../types";

// Constants
export const EXCLUDED_DIRS = new Set([
  "venv",
  ".venv",
  "site-packages",
  "__pycache__",
  "node_modules",
  ".git",
  "api_clients",
  "__test__",
  "rapidsnark",
  "test",
  "graph-node",
  "doc-images",
  "fixtures",
  ".yarn",
  ".changeset",
  ".github",
  "subgraph",
  "types",
  "autogenerated",
  "dist",
  "packages",
  "tools",
  "bindings",
]);

export const EXCLUDED_EXTENSIONS = [".json"];

const MAX_FILE_SIZE = 1024 * 1024; // 1MB

/**
 * Checks if a path should be excluded based on the EXCLUDED_DIRS set
 */
export function isExcluded(filePath: string): boolean {
  return filePath.split(path.sep).some((part) => EXCLUDED_DIRS.has(part));
}

/**
 * Collects files from a directory, filtering by allowed extensions
 */
export async function collectFiles(
  directory: string,
  allowedExtensions: string[],
  repoRoot: string
): Promise<CollectedFiles> {
  const fileTree: string[] = [];
  const pathToSourceCode: Record<string, string> = {};

  const processDirectory = async (
    dirPath: string,
    depth = 0,
    maxDepth = 5,
    maxFiles = 100
  ): Promise<void> => {
    if (depth > maxDepth || Object.keys(pathToSourceCode).length >= maxFiles) {
      return;
    }

    const dirEntries = await fs.readdir(dirPath, { withFileTypes: true });

    for (const entry of dirEntries) {
      const entryPath = path.join(dirPath, entry.name);
      const relativePath = path.relative(repoRoot, entryPath);

      if (entry.isDirectory()) {
        // Skip hidden directories and node_modules
        if (entry.name.startsWith(".") || entry.name === "node_modules") {
          continue;
        }

        fileTree.push(`${" ".repeat(depth * 2)}üìÅ ${entry.name}/`);
        await processDirectory(entryPath, depth + 1, maxDepth, maxFiles);
      } else if (entry.isFile()) {
        const ext = path.extname(entry.name);
        if (allowedExtensions.includes(ext)) {
          fileTree.push(`${" ".repeat(depth * 2)}üìÑ ${entry.name}`);

          if (Object.keys(pathToSourceCode).length < maxFiles) {
            try {
              const stats = await fs.stat(entryPath);
              if (stats.size <= MAX_FILE_SIZE) {
                const content = await fs.readFile(entryPath, "utf-8");
                pathToSourceCode[relativePath] = content;
              } else {
                pathToSourceCode[relativePath] = `File too large to include (${stats.size} bytes)`;
              }
            } catch (error) {
              logger.error(`Error reading file ${entryPath}: ${error}`);
            }
          }
        }
      }
    }
  };

  await processDirectory(directory);
  return { fileTree, pathToSourceCode };
}

/**
 * Reads source code from a list of file paths
 */
export async function getSourceCodeFromPaths(filePaths: string[]): Promise<Record<string, string>> {
  const pathToSourceCode: Record<string, string> = {};

  for (const filePath of filePaths) {
    try {
      const content = await fs.readFile(filePath, "utf-8");
      pathToSourceCode[filePath] = content;
    } catch (error) {
      pathToSourceCode[filePath] = `Error reading file: ${error}`;
      logger.error(`Could not read file ${filePath}: ${error}`);
    }
  }

  return pathToSourceCode;
}

/**
 * Generates a tree string representation from a list of file paths
 */
export function generateTreeString(filePaths: string[]): string {
  if (filePaths.length === 0) {
    return "No files found";
  }
  return filePaths.join("\n");
}

/**
 * Lists major directories in a repository
 */
export async function listMajorDirectories(repoPath: string): Promise<string[]> {
  const dirEntries = await fs.readdir(repoPath, { withFileTypes: true });
  const majorDirs: string[] = [];

  for (const entry of dirEntries) {
    if (entry.isDirectory() && !entry.name.startsWith(".") && entry.name !== "node_modules") {
      majorDirs.push(path.join(repoPath, entry.name));
    }
  }

  return majorDirs;
}
